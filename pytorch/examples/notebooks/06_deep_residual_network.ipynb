{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06_deep_residual_network.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":["aKIFn3pMc4_e"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"aKIFn3pMc4_e","colab_type":"text"},"cell_type":"markdown","source":["## Install"]},{"metadata":{"id":"4c9zNSftc5Sv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":117},"outputId":"40d8da5f-9c8e-4014-a474-fdaa65466cc1","executionInfo":{"status":"ok","timestamp":1527368750874,"user_tz":420,"elapsed":2363,"user":{"displayName":"Zhaoyang Xu","photoUrl":"//lh3.googleusercontent.com/-P706sVVgxyk/AAAAAAAAAAI/AAAAAAAAAEM/nAOSpZonVUE/s50-c-k-no/photo.jpg","userId":"107219502952715360534"}}},"cell_type":"code","source":["!pip3 install torch torchvision numpy"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.0)\r\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\r\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.3)\r\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\r\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.1.0)\r\n"],"name":"stdout"}]},{"metadata":{"id":"SxBzO4YPb1-r","colab_type":"text"},"cell_type":"markdown","source":["## Imports"]},{"metadata":{"id":"d0meQMvWbx1J","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from matplotlib import pyplot as plt\n","import numpy as np\n","\n","import torch as th\n","from torch import nn\n","import torchvision\n","from torchvision import transforms"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YUvDtaLcgN9c","colab_type":"text"},"cell_type":"markdown","source":["## Config"]},{"metadata":{"id":"iELDlX4IgRbf","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"02b1659c-4603-480f-d159-47f8683ddd5b","executionInfo":{"status":"ok","timestamp":1527541730618,"user_tz":420,"elapsed":23,"user":{"displayName":"Zhaoyang Xu","photoUrl":"//lh3.googleusercontent.com/-P706sVVgxyk/AAAAAAAAAAI/AAAAAAAAAEM/nAOSpZonVUE/s50-c-k-no/photo.jpg","userId":"107219502952715360534"}}},"cell_type":"code","source":["device = th.device('cuda' if th.cuda.is_available() else 'cpu')\n","print(f'Using {device}')\n","\n","num_epochs = 80\n","batch_size = 100\n","learning_rate = 0.001"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using cuda\n"],"name":"stdout"}]},{"metadata":{"id":"Iw65ZrYoNjhN","colab_type":"text"},"cell_type":"markdown","source":["## CIFAR-10 Dataset"]},{"metadata":{"id":"iE1C74EMNk1R","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":57},"outputId":"76c8a59a-66f7-424a-86ee-7badc46c3a02","executionInfo":{"status":"ok","timestamp":1527541769880,"user_tz":420,"elapsed":1117,"user":{"displayName":"Zhaoyang Xu","photoUrl":"//lh3.googleusercontent.com/-P706sVVgxyk/AAAAAAAAAAI/AAAAAAAAAEM/nAOSpZonVUE/s50-c-k-no/photo.jpg","userId":"107219502952715360534"}}},"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.Pad(4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomCrop(32),\n","    transforms.ToTensor(),\n","])\n","\n","train_dataset = torchvision.datasets.CIFAR10(\n","    root='~/code/data/cifar10/',\n","    train=True,\n","    transform=transform,\n","    download=True)\n","test_dataset = torchvision.datasets.CIFAR10(\n","    root='~/code/data/cifar10/',\n","    train=False,\n","    transform=transforms.ToTensor(),\n","    download=True)\n","\n","# Data loader (input pipeline)\n","train_loader = th.utils.data.DataLoader(dataset=train_dataset,\n","                                        batch_size=batch_size,\n","                                        shuffle=True)\n","test_loader = th.utils.data.DataLoader(dataset=test_dataset,\n","                                       batch_size=batch_size,\n","                                       shuffle=False)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"metadata":{"id":"W76Cu2HGNOMd","colab_type":"text"},"cell_type":"markdown","source":["## Model"]},{"metadata":{"id":"jbhrDxYRNQ5t","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# 3x3 convolution.\n","def conv3x3(in_channels, out_channels, stride=1):\n","  return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride,\n","                   padding=1, bias=False)\n","\n","# Residual block.\n","class ResidualBlock(nn.Module):\n","  def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n","    super().__init__()\n","    self.conv1 = conv3x3(in_channels, out_channels, stride)\n","    self.bn1 = nn.BatchNorm2d(out_channels)\n","    self.relu = nn.ReLU(inplace=True)\n","    self.conv2 = conv3x3(out_channels, out_channels)\n","    self.bn2 = nn.BatchNorm2d(out_channels)\n","    self.downsample = downsample\n","    \n","  def forward(self, x):\n","    out = self.conv1(x)\n","    out = self.bn1(out)\n","    out = self.relu(out)\n","    out = self.conv2(out)\n","    out = self.bn2(out)\n","    residual = x if not self.downsample else self.downsample(x)\n","    out += residual\n","    out = self.relu(out)\n","    return out\n","\n","# Residual layer with several blocks.\n","def residual_layer(block, in_channels, out_channels, num_blocks, stride=1):\n","  downsample = None\n","  if (stride != 1) or (in_channels != out_channels):\n","    downsample = nn.Sequential(\n","        conv3x3(in_channels, out_channels, stride=stride),\n","        nn.BatchNorm2d(out_channels),\n","    )\n","  layers = []\n","  layers.append(block(in_channels, out_channels, stride, downsample))\n","  for i in range(1, num_blocks):\n","    layers.append(block(out_channels, out_channels))\n","  return nn.Sequential(*layers)\n","\n","# ResNet\n","class ResNet(nn.Module):\n","  def __init__(self, block, block_counts, num_classes=10):\n","    super().__init__()\n","    self.conv = conv3x3(3, 16)\n","    self.bn = nn.BatchNorm2d(16)\n","    self.relu = nn.ReLU(inplace=True)\n","    self.layer1 = residual_layer(block, 16, 16, block_counts[0])\n","    self.layer2 = residual_layer(block, 16, 32, block_counts[1], stride=2)\n","    self.layer3 = residual_layer(block, 32, 64, block_counts[2], stride=2)\n","    self.avg_pool = nn.AvgPool2d(8)\n","    self.fc = nn.Linear(64, num_classes)\n","    \n","  def forward(self, x):\n","    out = self.conv(x)\n","    out = self.bn(out)\n","    out = self.relu(out)\n","    out = self.layer1(out)\n","    out = self.layer2(out)\n","    out = self.layer3(out)\n","    out = self.avg_pool(out)\n","    out = out.view(out.size(0), -1)\n","    out = self.fc(out)\n","    return out\n","\n","model = ResNet(ResidualBlock, [2, 2, 2]).to(device)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ircl6QxuOwNh","colab_type":"text"},"cell_type":"markdown","source":["## Train"]},{"metadata":{"id":"s_ZPCh7OOx7T","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":8017},"outputId":"a32c2662-ffa2-4de4-c1fb-d8866cfffdac","executionInfo":{"status":"ok","timestamp":1527544748486,"user_tz":420,"elapsed":581594,"user":{"displayName":"Zhaoyang Xu","photoUrl":"//lh3.googleusercontent.com/-P706sVVgxyk/AAAAAAAAAAI/AAAAAAAAAEM/nAOSpZonVUE/s50-c-k-no/photo.jpg","userId":"107219502952715360534"}}},"cell_type":"code","source":["# Loss and optimizer.\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = th.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Learning rate update.\n","def update_lr(optimizer, lr):\n","  for param_group in optimizer.param_groups:\n","    param_group['lr'] = lr\n","    \n","\n","num_steps = len(train_loader)\n","curr_lr = learning_rate\n","for epoch in range(num_epochs):\n","  for step, (images, labels) in enumerate(train_loader):\n","    images = images.to(device)\n","    labels = labels.to(device)\n","\n","    # Forward\n","    outputs = model(images)\n","    loss = loss_fn(outputs, labels)\n","    \n","    # Backward\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if (step + 1) % 100 == 0:\n","      print(f'Epoch [{epoch+1}/{num_epochs}], Step [{step+1}/{num_steps}], '\n","            f'Loss: {loss.item():.4}')\n","  \n","  # Decay learning rate.\n","  if (epoch + 1) % 20 == 0:\n","    curr_lr /= 3\n","    update_lr(optimizer, curr_lr)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch [1/80], Step [100/500], Loss: 1.711\n","Epoch [1/80], Step [200/500], Loss: 1.538\n","Epoch [1/80], Step [300/500], Loss: 1.442\n","Epoch [1/80], Step [400/500], Loss: 1.233\n","Epoch [1/80], Step [500/500], Loss: 1.146\n","Epoch [2/80], Step [100/500], Loss: 1.155\n","Epoch [2/80], Step [200/500], Loss: 1.047\n","Epoch [2/80], Step [300/500], Loss: 1.102\n","Epoch [2/80], Step [400/500], Loss: 0.9901\n","Epoch [2/80], Step [500/500], Loss: 0.916\n","Epoch [3/80], Step [100/500], Loss: 1.159\n","Epoch [3/80], Step [200/500], Loss: 0.9383\n","Epoch [3/80], Step [300/500], Loss: 0.8163\n","Epoch [3/80], Step [400/500], Loss: 0.8732\n","Epoch [3/80], Step [500/500], Loss: 0.7863\n","Epoch [4/80], Step [100/500], Loss: 0.6293\n","Epoch [4/80], Step [200/500], Loss: 0.948\n","Epoch [4/80], Step [300/500], Loss: 0.7323\n","Epoch [4/80], Step [400/500], Loss: 0.5984\n","Epoch [4/80], Step [500/500], Loss: 0.7478\n","Epoch [5/80], Step [100/500], Loss: 0.8586\n","Epoch [5/80], Step [200/500], Loss: 0.6831\n","Epoch [5/80], Step [300/500], Loss: 0.6886\n","Epoch [5/80], Step [400/500], Loss: 0.7533\n","Epoch [5/80], Step [500/500], Loss: 0.7432\n","Epoch [6/80], Step [100/500], Loss: 0.6129\n","Epoch [6/80], Step [200/500], Loss: 0.5887\n","Epoch [6/80], Step [300/500], Loss: 0.6963\n","Epoch [6/80], Step [400/500], Loss: 0.7545\n","Epoch [6/80], Step [500/500], Loss: 0.7635\n","Epoch [7/80], Step [100/500], Loss: 0.5299\n","Epoch [7/80], Step [200/500], Loss: 0.7243\n","Epoch [7/80], Step [300/500], Loss: 0.7011\n","Epoch [7/80], Step [400/500], Loss: 0.5998\n","Epoch [7/80], Step [500/500], Loss: 0.5873\n","Epoch [8/80], Step [100/500], Loss: 0.5737\n","Epoch [8/80], Step [200/500], Loss: 0.6777\n","Epoch [8/80], Step [300/500], Loss: 0.5516\n","Epoch [8/80], Step [400/500], Loss: 0.4893\n","Epoch [8/80], Step [500/500], Loss: 0.4406\n","Epoch [9/80], Step [100/500], Loss: 0.5365\n","Epoch [9/80], Step [200/500], Loss: 0.6374\n","Epoch [9/80], Step [300/500], Loss: 0.652\n","Epoch [9/80], Step [400/500], Loss: 0.5755\n","Epoch [9/80], Step [500/500], Loss: 0.5442\n","Epoch [10/80], Step [100/500], Loss: 0.5115\n","Epoch [10/80], Step [200/500], Loss: 0.5042\n","Epoch [10/80], Step [300/500], Loss: 0.5088\n","Epoch [10/80], Step [400/500], Loss: 0.6054\n","Epoch [10/80], Step [500/500], Loss: 0.5953\n","Epoch [11/80], Step [100/500], Loss: 0.3844\n","Epoch [11/80], Step [200/500], Loss: 0.4508\n","Epoch [11/80], Step [300/500], Loss: 0.6317\n","Epoch [11/80], Step [400/500], Loss: 0.4311\n","Epoch [11/80], Step [500/500], Loss: 0.579\n","Epoch [12/80], Step [100/500], Loss: 0.5188\n","Epoch [12/80], Step [200/500], Loss: 0.552\n","Epoch [12/80], Step [300/500], Loss: 0.5176\n","Epoch [12/80], Step [400/500], Loss: 0.3453\n","Epoch [12/80], Step [500/500], Loss: 0.5192\n","Epoch [13/80], Step [100/500], Loss: 0.3916\n","Epoch [13/80], Step [200/500], Loss: 0.427\n","Epoch [13/80], Step [300/500], Loss: 0.6006\n","Epoch [13/80], Step [400/500], Loss: 0.3097\n","Epoch [13/80], Step [500/500], Loss: 0.5761\n","Epoch [14/80], Step [100/500], Loss: 0.4372\n","Epoch [14/80], Step [200/500], Loss: 0.4122\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [14/80], Step [300/500], Loss: 0.4608\n","Epoch [14/80], Step [400/500], Loss: 0.3135\n","Epoch [14/80], Step [500/500], Loss: 0.4462\n","Epoch [15/80], Step [100/500], Loss: 0.5551\n","Epoch [15/80], Step [200/500], Loss: 0.6233\n","Epoch [15/80], Step [300/500], Loss: 0.5657\n","Epoch [15/80], Step [400/500], Loss: 0.3665\n","Epoch [15/80], Step [500/500], Loss: 0.4609\n","Epoch [16/80], Step [100/500], Loss: 0.3753\n","Epoch [16/80], Step [200/500], Loss: 0.5481\n","Epoch [16/80], Step [300/500], Loss: 0.6467\n","Epoch [16/80], Step [400/500], Loss: 0.4033\n","Epoch [16/80], Step [500/500], Loss: 0.4289\n","Epoch [17/80], Step [100/500], Loss: 0.4285\n","Epoch [17/80], Step [200/500], Loss: 0.284\n","Epoch [17/80], Step [300/500], Loss: 0.3859\n","Epoch [17/80], Step [400/500], Loss: 0.3915\n","Epoch [17/80], Step [500/500], Loss: 0.2972\n","Epoch [18/80], Step [100/500], Loss: 0.3581\n","Epoch [18/80], Step [200/500], Loss: 0.3169\n","Epoch [18/80], Step [300/500], Loss: 0.2848\n","Epoch [18/80], Step [400/500], Loss: 0.324\n","Epoch [18/80], Step [500/500], Loss: 0.3156\n","Epoch [19/80], Step [100/500], Loss: 0.3081\n","Epoch [19/80], Step [200/500], Loss: 0.3811\n","Epoch [19/80], Step [300/500], Loss: 0.3929\n","Epoch [19/80], Step [400/500], Loss: 0.35\n","Epoch [19/80], Step [500/500], Loss: 0.4049\n","Epoch [20/80], Step [100/500], Loss: 0.3175\n","Epoch [20/80], Step [200/500], Loss: 0.3476\n","Epoch [20/80], Step [300/500], Loss: 0.358\n","Epoch [20/80], Step [400/500], Loss: 0.4378\n","Epoch [20/80], Step [500/500], Loss: 0.2861\n","Epoch [21/80], Step [100/500], Loss: 0.2473\n","Epoch [21/80], Step [200/500], Loss: 0.1641\n","Epoch [21/80], Step [300/500], Loss: 0.2107\n","Epoch [21/80], Step [400/500], Loss: 0.3182\n","Epoch [21/80], Step [500/500], Loss: 0.2236\n","Epoch [22/80], Step [100/500], Loss: 0.2619\n","Epoch [22/80], Step [200/500], Loss: 0.3452\n","Epoch [22/80], Step [300/500], Loss: 0.3842\n","Epoch [22/80], Step [400/500], Loss: 0.4148\n","Epoch [22/80], Step [500/500], Loss: 0.1704\n","Epoch [23/80], Step [100/500], Loss: 0.3758\n","Epoch [23/80], Step [200/500], Loss: 0.3287\n","Epoch [23/80], Step [300/500], Loss: 0.2112\n","Epoch [23/80], Step [400/500], Loss: 0.2753\n","Epoch [23/80], Step [500/500], Loss: 0.2854\n","Epoch [24/80], Step [100/500], Loss: 0.3485\n","Epoch [24/80], Step [200/500], Loss: 0.3387\n","Epoch [24/80], Step [300/500], Loss: 0.2852\n","Epoch [24/80], Step [400/500], Loss: 0.2193\n","Epoch [24/80], Step [500/500], Loss: 0.2262\n","Epoch [25/80], Step [100/500], Loss: 0.3193\n","Epoch [25/80], Step [200/500], Loss: 0.3079\n","Epoch [25/80], Step [300/500], Loss: 0.2417\n","Epoch [25/80], Step [400/500], Loss: 0.2639\n","Epoch [25/80], Step [500/500], Loss: 0.3003\n","Epoch [26/80], Step [100/500], Loss: 0.2187\n","Epoch [26/80], Step [200/500], Loss: 0.2176\n","Epoch [26/80], Step [300/500], Loss: 0.3414\n","Epoch [26/80], Step [400/500], Loss: 0.1902\n","Epoch [26/80], Step [500/500], Loss: 0.2241\n","Epoch [27/80], Step [100/500], Loss: 0.311\n","Epoch [27/80], Step [200/500], Loss: 0.1804\n","Epoch [27/80], Step [300/500], Loss: 0.1508\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [27/80], Step [400/500], Loss: 0.2027\n","Epoch [27/80], Step [500/500], Loss: 0.258\n","Epoch [28/80], Step [100/500], Loss: 0.2994\n","Epoch [28/80], Step [200/500], Loss: 0.367\n","Epoch [28/80], Step [300/500], Loss: 0.2483\n","Epoch [28/80], Step [400/500], Loss: 0.2916\n","Epoch [28/80], Step [500/500], Loss: 0.1852\n","Epoch [29/80], Step [100/500], Loss: 0.2242\n","Epoch [29/80], Step [200/500], Loss: 0.3158\n","Epoch [29/80], Step [300/500], Loss: 0.3571\n","Epoch [29/80], Step [400/500], Loss: 0.3707\n","Epoch [29/80], Step [500/500], Loss: 0.2543\n","Epoch [30/80], Step [100/500], Loss: 0.2209\n","Epoch [30/80], Step [200/500], Loss: 0.2618\n","Epoch [30/80], Step [300/500], Loss: 0.2028\n","Epoch [30/80], Step [400/500], Loss: 0.2935\n","Epoch [30/80], Step [500/500], Loss: 0.2072\n","Epoch [31/80], Step [100/500], Loss: 0.2393\n","Epoch [31/80], Step [200/500], Loss: 0.2948\n","Epoch [31/80], Step [300/500], Loss: 0.3133\n","Epoch [31/80], Step [400/500], Loss: 0.2679\n","Epoch [31/80], Step [500/500], Loss: 0.3198\n","Epoch [32/80], Step [100/500], Loss: 0.3654\n","Epoch [32/80], Step [200/500], Loss: 0.2431\n","Epoch [32/80], Step [300/500], Loss: 0.2789\n","Epoch [32/80], Step [400/500], Loss: 0.2864\n","Epoch [32/80], Step [500/500], Loss: 0.2771\n","Epoch [33/80], Step [100/500], Loss: 0.2246\n","Epoch [33/80], Step [200/500], Loss: 0.2758\n","Epoch [33/80], Step [300/500], Loss: 0.1981\n","Epoch [33/80], Step [400/500], Loss: 0.3094\n","Epoch [33/80], Step [500/500], Loss: 0.4301\n","Epoch [34/80], Step [100/500], Loss: 0.1509\n","Epoch [34/80], Step [200/500], Loss: 0.1662\n","Epoch [34/80], Step [300/500], Loss: 0.1339\n","Epoch [34/80], Step [400/500], Loss: 0.1688\n","Epoch [34/80], Step [500/500], Loss: 0.2091\n","Epoch [35/80], Step [100/500], Loss: 0.1235\n","Epoch [35/80], Step [200/500], Loss: 0.2293\n","Epoch [35/80], Step [300/500], Loss: 0.282\n","Epoch [35/80], Step [400/500], Loss: 0.2601\n","Epoch [35/80], Step [500/500], Loss: 0.4599\n","Epoch [36/80], Step [100/500], Loss: 0.3072\n","Epoch [36/80], Step [200/500], Loss: 0.1889\n","Epoch [36/80], Step [300/500], Loss: 0.2804\n","Epoch [36/80], Step [400/500], Loss: 0.2684\n","Epoch [36/80], Step [500/500], Loss: 0.2729\n","Epoch [37/80], Step [100/500], Loss: 0.244\n","Epoch [37/80], Step [200/500], Loss: 0.3034\n","Epoch [37/80], Step [300/500], Loss: 0.1724\n","Epoch [37/80], Step [400/500], Loss: 0.2932\n","Epoch [37/80], Step [500/500], Loss: 0.3897\n","Epoch [38/80], Step [100/500], Loss: 0.2175\n","Epoch [38/80], Step [200/500], Loss: 0.1435\n","Epoch [38/80], Step [300/500], Loss: 0.1389\n","Epoch [38/80], Step [400/500], Loss: 0.3693\n","Epoch [38/80], Step [500/500], Loss: 0.1622\n","Epoch [39/80], Step [100/500], Loss: 0.2296\n","Epoch [39/80], Step [200/500], Loss: 0.2056\n","Epoch [39/80], Step [300/500], Loss: 0.3316\n","Epoch [39/80], Step [400/500], Loss: 0.38\n","Epoch [39/80], Step [500/500], Loss: 0.2916\n","Epoch [40/80], Step [100/500], Loss: 0.2732\n","Epoch [40/80], Step [200/500], Loss: 0.1849\n","Epoch [40/80], Step [300/500], Loss: 0.1933\n","Epoch [40/80], Step [400/500], Loss: 0.234\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [40/80], Step [500/500], Loss: 0.1724\n","Epoch [41/80], Step [100/500], Loss: 0.219\n","Epoch [41/80], Step [200/500], Loss: 0.07018\n","Epoch [41/80], Step [300/500], Loss: 0.2831\n","Epoch [41/80], Step [400/500], Loss: 0.2509\n","Epoch [41/80], Step [500/500], Loss: 0.3095\n","Epoch [42/80], Step [100/500], Loss: 0.1266\n","Epoch [42/80], Step [200/500], Loss: 0.2\n","Epoch [42/80], Step [300/500], Loss: 0.1179\n","Epoch [42/80], Step [400/500], Loss: 0.1778\n","Epoch [42/80], Step [500/500], Loss: 0.1977\n","Epoch [43/80], Step [100/500], Loss: 0.1754\n","Epoch [43/80], Step [200/500], Loss: 0.1131\n","Epoch [43/80], Step [300/500], Loss: 0.1942\n","Epoch [43/80], Step [400/500], Loss: 0.2143\n","Epoch [43/80], Step [500/500], Loss: 0.2518\n","Epoch [44/80], Step [100/500], Loss: 0.1977\n","Epoch [44/80], Step [200/500], Loss: 0.1878\n","Epoch [44/80], Step [300/500], Loss: 0.1396\n","Epoch [44/80], Step [400/500], Loss: 0.07896\n","Epoch [44/80], Step [500/500], Loss: 0.2089\n","Epoch [45/80], Step [100/500], Loss: 0.2353\n","Epoch [45/80], Step [200/500], Loss: 0.1067\n","Epoch [45/80], Step [300/500], Loss: 0.1455\n","Epoch [45/80], Step [400/500], Loss: 0.2908\n","Epoch [45/80], Step [500/500], Loss: 0.3035\n","Epoch [46/80], Step [100/500], Loss: 0.2088\n","Epoch [46/80], Step [200/500], Loss: 0.1365\n","Epoch [46/80], Step [300/500], Loss: 0.2104\n","Epoch [46/80], Step [400/500], Loss: 0.2425\n","Epoch [46/80], Step [500/500], Loss: 0.1286\n","Epoch [47/80], Step [100/500], Loss: 0.169\n","Epoch [47/80], Step [200/500], Loss: 0.1851\n","Epoch [47/80], Step [300/500], Loss: 0.1896\n","Epoch [47/80], Step [400/500], Loss: 0.2082\n","Epoch [47/80], Step [500/500], Loss: 0.2337\n","Epoch [48/80], Step [100/500], Loss: 0.2141\n","Epoch [48/80], Step [200/500], Loss: 0.1895\n","Epoch [48/80], Step [300/500], Loss: 0.1645\n","Epoch [48/80], Step [400/500], Loss: 0.2728\n","Epoch [48/80], Step [500/500], Loss: 0.1335\n","Epoch [49/80], Step [100/500], Loss: 0.1537\n","Epoch [49/80], Step [200/500], Loss: 0.1703\n","Epoch [49/80], Step [300/500], Loss: 0.125\n","Epoch [49/80], Step [400/500], Loss: 0.1135\n","Epoch [49/80], Step [500/500], Loss: 0.2759\n","Epoch [50/80], Step [100/500], Loss: 0.1397\n","Epoch [50/80], Step [200/500], Loss: 0.1153\n","Epoch [50/80], Step [300/500], Loss: 0.2672\n","Epoch [50/80], Step [400/500], Loss: 0.1297\n","Epoch [50/80], Step [500/500], Loss: 0.2024\n","Epoch [51/80], Step [100/500], Loss: 0.2145\n","Epoch [51/80], Step [200/500], Loss: 0.1607\n","Epoch [51/80], Step [300/500], Loss: 0.1439\n","Epoch [51/80], Step [400/500], Loss: 0.127\n","Epoch [51/80], Step [500/500], Loss: 0.1846\n","Epoch [52/80], Step [100/500], Loss: 0.2015\n","Epoch [52/80], Step [200/500], Loss: 0.1838\n","Epoch [52/80], Step [300/500], Loss: 0.1952\n","Epoch [52/80], Step [400/500], Loss: 0.2378\n","Epoch [52/80], Step [500/500], Loss: 0.2262\n","Epoch [53/80], Step [100/500], Loss: 0.1905\n","Epoch [53/80], Step [200/500], Loss: 0.192\n","Epoch [53/80], Step [300/500], Loss: 0.1054\n","Epoch [53/80], Step [400/500], Loss: 0.1471\n","Epoch [53/80], Step [500/500], Loss: 0.1755\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [54/80], Step [100/500], Loss: 0.2042\n","Epoch [54/80], Step [200/500], Loss: 0.3252\n","Epoch [54/80], Step [300/500], Loss: 0.1563\n","Epoch [54/80], Step [400/500], Loss: 0.2023\n","Epoch [54/80], Step [500/500], Loss: 0.1492\n","Epoch [55/80], Step [100/500], Loss: 0.2223\n","Epoch [55/80], Step [200/500], Loss: 0.2036\n","Epoch [55/80], Step [300/500], Loss: 0.2828\n","Epoch [55/80], Step [400/500], Loss: 0.1725\n","Epoch [55/80], Step [500/500], Loss: 0.128\n","Epoch [56/80], Step [100/500], Loss: 0.1771\n","Epoch [56/80], Step [200/500], Loss: 0.07497\n","Epoch [56/80], Step [300/500], Loss: 0.2644\n","Epoch [56/80], Step [400/500], Loss: 0.1623\n","Epoch [56/80], Step [500/500], Loss: 0.2105\n","Epoch [57/80], Step [100/500], Loss: 0.1762\n","Epoch [57/80], Step [200/500], Loss: 0.1549\n","Epoch [57/80], Step [300/500], Loss: 0.2236\n","Epoch [57/80], Step [400/500], Loss: 0.286\n","Epoch [57/80], Step [500/500], Loss: 0.2549\n","Epoch [58/80], Step [100/500], Loss: 0.1637\n","Epoch [58/80], Step [200/500], Loss: 0.2434\n","Epoch [58/80], Step [300/500], Loss: 0.1628\n","Epoch [58/80], Step [400/500], Loss: 0.1377\n","Epoch [58/80], Step [500/500], Loss: 0.1903\n","Epoch [59/80], Step [100/500], Loss: 0.09399\n","Epoch [59/80], Step [200/500], Loss: 0.1175\n","Epoch [59/80], Step [300/500], Loss: 0.1438\n","Epoch [59/80], Step [400/500], Loss: 0.1016\n","Epoch [59/80], Step [500/500], Loss: 0.2162\n","Epoch [60/80], Step [100/500], Loss: 0.2061\n","Epoch [60/80], Step [200/500], Loss: 0.08065\n","Epoch [60/80], Step [300/500], Loss: 0.1982\n","Epoch [60/80], Step [400/500], Loss: 0.1641\n","Epoch [60/80], Step [500/500], Loss: 0.1968\n","Epoch [61/80], Step [100/500], Loss: 0.197\n","Epoch [61/80], Step [200/500], Loss: 0.1024\n","Epoch [61/80], Step [300/500], Loss: 0.2697\n","Epoch [61/80], Step [400/500], Loss: 0.1564\n","Epoch [61/80], Step [500/500], Loss: 0.0758\n","Epoch [62/80], Step [100/500], Loss: 0.2023\n","Epoch [62/80], Step [200/500], Loss: 0.1588\n","Epoch [62/80], Step [300/500], Loss: 0.1912\n","Epoch [62/80], Step [400/500], Loss: 0.1644\n","Epoch [62/80], Step [500/500], Loss: 0.1493\n","Epoch [63/80], Step [100/500], Loss: 0.07649\n","Epoch [63/80], Step [200/500], Loss: 0.1199\n","Epoch [63/80], Step [300/500], Loss: 0.1465\n","Epoch [63/80], Step [400/500], Loss: 0.08286\n","Epoch [63/80], Step [500/500], Loss: 0.122\n","Epoch [64/80], Step [100/500], Loss: 0.2848\n","Epoch [64/80], Step [200/500], Loss: 0.1708\n","Epoch [64/80], Step [300/500], Loss: 0.1443\n","Epoch [64/80], Step [400/500], Loss: 0.1648\n","Epoch [64/80], Step [500/500], Loss: 0.1753\n","Epoch [65/80], Step [100/500], Loss: 0.1613\n","Epoch [65/80], Step [200/500], Loss: 0.1724\n","Epoch [65/80], Step [300/500], Loss: 0.1398\n","Epoch [65/80], Step [400/500], Loss: 0.1332\n","Epoch [65/80], Step [500/500], Loss: 0.1744\n","Epoch [66/80], Step [100/500], Loss: 0.07456\n","Epoch [66/80], Step [200/500], Loss: 0.1168\n","Epoch [66/80], Step [300/500], Loss: 0.1286\n","Epoch [66/80], Step [400/500], Loss: 0.2579\n","Epoch [66/80], Step [500/500], Loss: 0.1764\n","Epoch [67/80], Step [100/500], Loss: 0.06406\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [67/80], Step [200/500], Loss: 0.1054\n","Epoch [67/80], Step [300/500], Loss: 0.168\n","Epoch [67/80], Step [400/500], Loss: 0.09866\n","Epoch [67/80], Step [500/500], Loss: 0.09712\n","Epoch [68/80], Step [100/500], Loss: 0.25\n","Epoch [68/80], Step [200/500], Loss: 0.08042\n","Epoch [68/80], Step [300/500], Loss: 0.1209\n","Epoch [68/80], Step [400/500], Loss: 0.1039\n","Epoch [68/80], Step [500/500], Loss: 0.1045\n","Epoch [69/80], Step [100/500], Loss: 0.2255\n","Epoch [69/80], Step [200/500], Loss: 0.1349\n","Epoch [69/80], Step [300/500], Loss: 0.1225\n","Epoch [69/80], Step [400/500], Loss: 0.2016\n","Epoch [69/80], Step [500/500], Loss: 0.1131\n","Epoch [70/80], Step [100/500], Loss: 0.172\n","Epoch [70/80], Step [200/500], Loss: 0.1455\n","Epoch [70/80], Step [300/500], Loss: 0.09429\n","Epoch [70/80], Step [400/500], Loss: 0.08697\n","Epoch [70/80], Step [500/500], Loss: 0.1469\n","Epoch [71/80], Step [100/500], Loss: 0.1391\n","Epoch [71/80], Step [200/500], Loss: 0.1861\n","Epoch [71/80], Step [300/500], Loss: 0.2539\n","Epoch [71/80], Step [400/500], Loss: 0.2464\n","Epoch [71/80], Step [500/500], Loss: 0.1328\n","Epoch [72/80], Step [100/500], Loss: 0.2234\n","Epoch [72/80], Step [200/500], Loss: 0.1093\n","Epoch [72/80], Step [300/500], Loss: 0.1699\n","Epoch [72/80], Step [400/500], Loss: 0.06503\n","Epoch [72/80], Step [500/500], Loss: 0.08618\n","Epoch [73/80], Step [100/500], Loss: 0.1096\n","Epoch [73/80], Step [200/500], Loss: 0.1379\n","Epoch [73/80], Step [300/500], Loss: 0.1752\n","Epoch [73/80], Step [400/500], Loss: 0.2175\n","Epoch [73/80], Step [500/500], Loss: 0.1367\n","Epoch [74/80], Step [100/500], Loss: 0.1378\n","Epoch [74/80], Step [200/500], Loss: 0.1772\n","Epoch [74/80], Step [300/500], Loss: 0.1097\n","Epoch [74/80], Step [400/500], Loss: 0.2657\n","Epoch [74/80], Step [500/500], Loss: 0.1526\n","Epoch [75/80], Step [100/500], Loss: 0.1156\n","Epoch [75/80], Step [200/500], Loss: 0.1306\n","Epoch [75/80], Step [300/500], Loss: 0.07274\n","Epoch [75/80], Step [400/500], Loss: 0.1937\n","Epoch [75/80], Step [500/500], Loss: 0.1991\n","Epoch [76/80], Step [100/500], Loss: 0.1914\n","Epoch [76/80], Step [200/500], Loss: 0.2016\n","Epoch [76/80], Step [300/500], Loss: 0.1206\n","Epoch [76/80], Step [400/500], Loss: 0.187\n","Epoch [76/80], Step [500/500], Loss: 0.1603\n","Epoch [77/80], Step [100/500], Loss: 0.2741\n","Epoch [77/80], Step [200/500], Loss: 0.1088\n","Epoch [77/80], Step [300/500], Loss: 0.1899\n","Epoch [77/80], Step [400/500], Loss: 0.1678\n","Epoch [77/80], Step [500/500], Loss: 0.1241\n","Epoch [78/80], Step [100/500], Loss: 0.1982\n","Epoch [78/80], Step [200/500], Loss: 0.1913\n","Epoch [78/80], Step [300/500], Loss: 0.1661\n","Epoch [78/80], Step [400/500], Loss: 0.1667\n","Epoch [78/80], Step [500/500], Loss: 0.2488\n","Epoch [79/80], Step [100/500], Loss: 0.1536\n","Epoch [79/80], Step [200/500], Loss: 0.09805\n","Epoch [79/80], Step [300/500], Loss: 0.1508\n","Epoch [79/80], Step [400/500], Loss: 0.121\n","Epoch [79/80], Step [500/500], Loss: 0.07109\n","Epoch [80/80], Step [100/500], Loss: 0.1832\n","Epoch [80/80], Step [200/500], Loss: 0.1813\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch [80/80], Step [300/500], Loss: 0.1519\n","Epoch [80/80], Step [400/500], Loss: 0.2194\n","Epoch [80/80], Step [500/500], Loss: 0.1939\n"],"name":"stdout"}]},{"metadata":{"id":"votDXSLhR8Be","colab_type":"text"},"cell_type":"markdown","source":["## Test"]},{"metadata":{"id":"6y216f2uR9VQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"ba7cec08-0b46-42de-e73d-069c4660b7a3","executionInfo":{"status":"ok","timestamp":1527545928317,"user_tz":420,"elapsed":888,"user":{"displayName":"Zhaoyang Xu","photoUrl":"//lh3.googleusercontent.com/-P706sVVgxyk/AAAAAAAAAAI/AAAAAAAAAEM/nAOSpZonVUE/s50-c-k-no/photo.jpg","userId":"107219502952715360534"}}},"cell_type":"code","source":["with th.no_grad():\n","  correct, total = 0, 0\n","  for images, labels in test_loader:\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    outputs = model(images)\n","    _, predicted = th.max(outputs.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum().item()\n","  accuracy = correct / total\n","  print(f'Accuracy of model on 10000 test images: {100 * accuracy:0.2f}%')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Accuracy of model on 10000 test images: 85.33%\n"],"name":"stdout"}]},{"metadata":{"id":"kWadwB94Wyqe","colab_type":"text"},"cell_type":"markdown","source":["## Save model"]},{"metadata":{"id":"7JzujefLWyGn","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["th.save(model.state_dict(), '/tmp/resnet.ckpt')"],"execution_count":0,"outputs":[]}]}