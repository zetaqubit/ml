{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"13_conv_rnn.ipynb","version":"0.3.2","provenance":[{"file_id":"1z5lU6SLtvzTlSP1Ue4B2bSD7rBxavNAZ","timestamp":1545691441294},{"file_id":"1wFoi310s4KSIzbuLZdBC75sn4SwWQeP5","timestamp":1527953769581}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"iAhwExDiZRsU","colab_type":"text"},"cell_type":"markdown","source":["## Description"]},{"metadata":{"id":"TdEX4i5BZgzK","colab_type":"text"},"cell_type":"markdown","source":["**Dataset**\n","\n","Each example is a sequence of T random MNIST digits. Goal is to predict the sum.\n","\n","**Model**\n","\n","A CNN processes each digit. The activations are fed into an LSTM.\n","\n"]},{"metadata":{"id":"aKIFn3pMc4_e","colab_type":"text"},"cell_type":"markdown","source":["## Install"]},{"metadata":{"id":"4c9zNSftc5Sv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":132},"outputId":"2afca805-fa2f-4434-c67b-f232863f4663","executionInfo":{"status":"ok","timestamp":1548842814578,"user_tz":480,"elapsed":577,"user":{"displayName":"zetaqubit","photoUrl":"","userId":"03601982979073205738"}}},"cell_type":"code","source":["!pip3 install torch torchvision numpy"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/lib/python3.7/site-packages (1.0.0)\r\n","Requirement already satisfied: torchvision in /usr/lib/python3.7/site-packages (0.2.1)\r\n","Requirement already satisfied: numpy in /usr/lib/python3.7/site-packages (1.15.4)\r\n","Requirement already satisfied: six in /usr/lib/python3.7/site-packages (from torchvision) (1.12.0)\r\n","Requirement already satisfied: pillow>=4.1.1 in /usr/lib/python3.7/site-packages (from torchvision) (5.4.1)\r\n","Requirement already satisfied: tqdm in /usr/lib/python3.7/site-packages (from torchvision) (4.29.1)\r\n"],"name":"stdout"}]},{"metadata":{"id":"SxBzO4YPb1-r","colab_type":"text"},"cell_type":"markdown","source":["## Imports"]},{"metadata":{"id":"d0meQMvWbx1J","colab_type":"code","colab":{}},"cell_type":"code","source":["from matplotlib import pyplot as plt\n","import numpy as np\n","\n","import torch as th\n","from torch import nn\n","import torchvision\n","from torchvision import transforms"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YUvDtaLcgN9c","colab_type":"text"},"cell_type":"markdown","source":["## Config"]},{"metadata":{"id":"iELDlX4IgRbf","colab_type":"code","outputId":"b7beda13-9a77-4646-fe01-36ba9e3725e6","executionInfo":{"status":"ok","timestamp":1548842814986,"user_tz":480,"elapsed":955,"user":{"displayName":"zetaqubit","photoUrl":"","userId":"03601982979073205738"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["debug = False\n","device = th.device('cuda' if th.cuda.is_available() and not debug else 'cpu')\n","print(f'Using {device}')\n","\n","\n","\n","sequence_length = 2\n","conv_out_size = 64\n","hidden_size = 128\n","num_layers = 2\n","num_classes = 1 + 9 * sequence_length\n","\n","num_epochs = 10\n","batch_size = 100\n","learning_rate = 0.001"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using cuda\n"],"name":"stdout"}]},{"metadata":{"id":"BCGWvI2KKH9-","colab_type":"text"},"cell_type":"markdown","source":["## Dataset: MNIST Pair Sum "]},{"metadata":{"id":"nxMMkca8KH9-","colab_type":"code","colab":{}},"cell_type":"code","source":["# Download and construct MNIST dataset.\n","train_dataset = torchvision.datasets.MNIST(root='~/code/data/mnist/',\n","                                           train=True,\n","                                           transform=transforms.ToTensor(),\n","                                           download=True)\n","test_dataset = torchvision.datasets.MNIST(root='~/code/data/mnist/',\n","                                          train=False,\n","                                          transform=transforms.ToTensor(),\n","                                          download=True)\n","\n","# Data loader (input pipeline)\n","train_loader = th.utils.data.DataLoader(dataset=train_dataset,\n","                                        batch_size=sequence_length * batch_size,\n","                                        shuffle=True)\n","test_loader = th.utils.data.DataLoader(dataset=test_dataset,\n","                                       batch_size=sequence_length * batch_size,\n","                                       shuffle=False)\n","\n","def encode_sequence_data(images, labels):\n","  # Create sequence by chunking along batch dimension.\n","  # [batch, ...] -> [seq_len, batch, ...]\n","  assert images.size(0) % sequence_length == 0\n","  assert labels.size(0) % sequence_length == 0\n","  image_chunks = th.chunk(images, sequence_length)\n","  images = th.stack(image_chunks)\n","  label_chunks = th.chunk(labels, sequence_length)\n","  labels = th.stack(label_chunks)\n","  labels = th.sum(labels, dim=0)  # [seq_len, batch, ...] -> [batch, ...]\n","  return images, labels"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W76Cu2HGNOMd","colab_type":"text"},"cell_type":"markdown","source":["## Model (Conv RNN)"]},{"metadata":{"id":"Mkjmv-dHe0tt","colab_type":"code","colab":{}},"cell_type":"code","source":["# Convolutional neural network (with 2 convolutional layers).\n","class CNN(nn.Module):\n","  def __init__(self, num_outputs):\n","    super().__init__()\n","    self.layer1 = nn.Sequential(\n","        nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n","        nn.BatchNorm2d(16),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2),\n","    )\n","    self.layer2 = nn.Sequential(\n","        nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n","        nn.BatchNorm2d(32),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2),\n","    )\n","    self.fc = nn.Linear(7 * 7 * 32, num_outputs)\n","    \n","  def forward(self, x):\n","    out = self.layer1(x)\n","    out = self.layer2(out)\n","    out = out.reshape(out.size(0), -1)\n","    out = self.fc(out)\n","    return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jbhrDxYRNQ5t","colab_type":"code","colab":{}},"cell_type":"code","source":["class ConvRNN(nn.Module):\n","  def __init__(self, conv_net, conv_output_size, hidden_size, num_layers,\n","               num_classes):\n","    super(ConvRNN, self).__init__()\n","    self.conv_net = conv_net\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","    self.lstm = nn.LSTM(conv_output_size, hidden_size, num_layers)\n","    self.fc = nn.Linear(hidden_size, num_classes)\n","    \n","  def forward(self, x):\n","    \"\"\"\n","    Args:\n","      x: input tensor, shaped [seq_len, batch_size, channel, height, width]\n","    \"\"\"\n","    # Set initial hidden and cell states.\n","    h0 = th.zeros(self.num_layers, x.size(1), self.hidden_size).to(device)\n","    c0 = th.zeros(self.num_layers, x.size(1), self.hidden_size).to(device)\n","    \n","    # Apply conv_net to get activations.\n","    orig_shape = x.shape\n","    combined_batch_shape = th.Size([-1]) + x.shape[2:]\n","    x = x.view(*combined_batch_shape)\n","    conv_outs = self.conv_net(x)\n","    conv_outs = conv_outs.view(orig_shape[:2] + th.Size([-1]))\n","    \n","    # Forward propagate LSTM.\n","    # out shape (seq_len, batch_size, hid_size)\n","    out, _ = self.lstm(conv_outs, (h0, c0))\n","    \n","    # Decode the hidden state of the last time step.\n","    out = self.fc(out[-1, :, :])\n","    return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cTL353p6fNeI","colab_type":"code","colab":{}},"cell_type":"code","source":["cnn = CNN(conv_out_size)\n","model = ConvRNN(cnn, conv_out_size, hidden_size, num_layers, num_classes).to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ircl6QxuOwNh","colab_type":"text"},"cell_type":"markdown","source":["## Train"]},{"metadata":{"id":"s_ZPCh7OOx7T","colab_type":"code","outputId":"df519c8e-0d70-4512-8318-a948cb68cba7","executionInfo":{"status":"ok","timestamp":1548842858726,"user_tz":480,"elapsed":44670,"user":{"displayName":"zetaqubit","photoUrl":"","userId":"03601982979073205738"}},"colab":{"base_uri":"https://localhost:8080/","height":593}},"cell_type":"code","source":["# Loss and optimizer.\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = th.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","\n","num_steps = len(train_loader)\n","for epoch in range(num_epochs):\n","  for step, (images, labels) in enumerate(train_loader):\n","    images, labels = encode_sequence_data(images, labels)\n","    images = images.to(device)\n","    labels = labels.to(device)\n","\n","    # Forward\n","    outputs = model(images)\n","    loss = loss_fn(outputs, labels)\n","    \n","    # Backward\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if (step + 1) % 100 == 0:\n","      print(f'Epoch [{epoch+1}/{num_epochs}], Step [{step+1}/{num_steps}], '\n","            f'Loss: {loss.item():.4}')  "],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch [1/10], Step [100/300], Loss: 2.053\n","Epoch [1/10], Step [200/300], Loss: 1.538\n","Epoch [1/10], Step [300/300], Loss: 1.16\n","Epoch [2/10], Step [100/300], Loss: 0.938\n","Epoch [2/10], Step [200/300], Loss: 0.7223\n","Epoch [2/10], Step [300/300], Loss: 0.7639\n","Epoch [3/10], Step [100/300], Loss: 0.3452\n","Epoch [3/10], Step [200/300], Loss: 0.3157\n","Epoch [3/10], Step [300/300], Loss: 0.2034\n","Epoch [4/10], Step [100/300], Loss: 0.335\n","Epoch [4/10], Step [200/300], Loss: 0.2182\n","Epoch [4/10], Step [300/300], Loss: 0.3585\n","Epoch [5/10], Step [100/300], Loss: 0.2039\n","Epoch [5/10], Step [200/300], Loss: 0.1959\n","Epoch [5/10], Step [300/300], Loss: 0.08152\n","Epoch [6/10], Step [100/300], Loss: 0.1678\n","Epoch [6/10], Step [200/300], Loss: 0.09434\n","Epoch [6/10], Step [300/300], Loss: 0.1819\n","Epoch [7/10], Step [100/300], Loss: 0.09034\n","Epoch [7/10], Step [200/300], Loss: 0.1564\n","Epoch [7/10], Step [300/300], Loss: 0.06534\n","Epoch [8/10], Step [100/300], Loss: 0.08392\n","Epoch [8/10], Step [200/300], Loss: 0.106\n","Epoch [8/10], Step [300/300], Loss: 0.1566\n","Epoch [9/10], Step [100/300], Loss: 0.06204\n","Epoch [9/10], Step [200/300], Loss: 0.1041\n","Epoch [9/10], Step [300/300], Loss: 0.1081\n","Epoch [10/10], Step [100/300], Loss: 0.04475\n","Epoch [10/10], Step [200/300], Loss: 0.02354\n","Epoch [10/10], Step [300/300], Loss: 0.06109\n"],"name":"stdout"}]},{"metadata":{"id":"votDXSLhR8Be","colab_type":"text"},"cell_type":"markdown","source":["## Test"]},{"metadata":{"id":"6y216f2uR9VQ","colab_type":"code","outputId":"d46baca6-0429-4190-fff6-e71114c64d97","executionInfo":{"status":"ok","timestamp":1548842858727,"user_tz":480,"elapsed":44656,"user":{"displayName":"zetaqubit","photoUrl":"","userId":"03601982979073205738"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["with th.no_grad():\n","  correct, total = 0, 0\n","  for images, labels in test_loader:\n","    images, labels = encode_sequence_data(images, labels)\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    outputs = model(images)\n","    _, predicted = th.max(outputs.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum().item()\n","  accuracy = correct / total\n","  print(f'Accuracy of model on 10000 test images: {100 * accuracy:0.2f}%')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Accuracy of model on 10000 test images: 97.40%\n"],"name":"stdout"}]},{"metadata":{"id":"kWadwB94Wyqe","colab_type":"text"},"cell_type":"markdown","source":["## Save model"]},{"metadata":{"id":"7JzujefLWyGn","colab_type":"code","colab":{}},"cell_type":"code","source":["th.save(model.state_dict(), '/tmp/mnist_rnn.ckpt')"],"execution_count":0,"outputs":[]}]}