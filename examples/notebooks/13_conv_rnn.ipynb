{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"13_conv_rnn.ipynb","version":"0.3.2","provenance":[{"file_id":"1z5lU6SLtvzTlSP1Ue4B2bSD7rBxavNAZ","timestamp":1545691441294},{"file_id":"1wFoi310s4KSIzbuLZdBC75sn4SwWQeP5","timestamp":1527953769581}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"iAhwExDiZRsU","colab_type":"text"},"cell_type":"markdown","source":["## Description"]},{"metadata":{"id":"TdEX4i5BZgzK","colab_type":"text"},"cell_type":"markdown","source":["**Dataset**\n","\n","Each example is a sequence of T random MNIST digits. Goal is to predict the sum.\n","\n","**Model**\n","\n","A CNN processes each digit. The activations are fed into an LSTM.\n","\n"]},{"metadata":{"id":"aKIFn3pMc4_e","colab_type":"text"},"cell_type":"markdown","source":["## Install"]},{"metadata":{"id":"4c9zNSftc5Sv","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip3 install torch torchvision numpy"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SxBzO4YPb1-r","colab_type":"text"},"cell_type":"markdown","source":["## Imports"]},{"metadata":{"id":"d0meQMvWbx1J","colab_type":"code","colab":{}},"cell_type":"code","source":["from matplotlib import pyplot as plt\n","import numpy as np\n","\n","import torch as th\n","from torch import nn\n","import torchvision\n","from torchvision import transforms"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YUvDtaLcgN9c","colab_type":"text"},"cell_type":"markdown","source":["## Config"]},{"metadata":{"id":"iELDlX4IgRbf","colab_type":"code","outputId":"b9030e21-e8fa-454f-cb4d-1a9a571818c7","executionInfo":{"status":"ok","timestamp":1545710875165,"user_tz":480,"elapsed":14,"user":{"displayName":"Zhaoyang Xu","photoUrl":"https://lh3.googleusercontent.com/-P706sVVgxyk/AAAAAAAAAAI/AAAAAAAAAEM/nAOSpZonVUE/s64/photo.jpg","userId":"09107292472959224374"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["debug = False\n","device = th.device('cuda' if th.cuda.is_available() and not debug else 'cpu')\n","print(f'Using {device}')\n","\n","\n","\n","sequence_length = 2\n","conv_out_size = 64\n","hidden_size = 128\n","num_layers = 2\n","num_classes = 1 + 9 * sequence_length\n","\n","num_epochs = 10\n","batch_size = 100\n","learning_rate = 0.001"],"execution_count":91,"outputs":[{"output_type":"stream","text":["Using cuda\n"],"name":"stdout"}]},{"metadata":{"id":"BCGWvI2KKH9-","colab_type":"text"},"cell_type":"markdown","source":["## Dataset: MNIST Pair Sum "]},{"metadata":{"id":"nxMMkca8KH9-","colab_type":"code","colab":{}},"cell_type":"code","source":["# Download and construct MNIST dataset.\n","train_dataset = torchvision.datasets.MNIST(root='~/code/data/mnist/',\n","                                           train=True,\n","                                           transform=transforms.ToTensor(),\n","                                           download=True)\n","test_dataset = torchvision.datasets.MNIST(root='~/code/data/mnist/',\n","                                          train=False,\n","                                          transform=transforms.ToTensor(),\n","                                          download=True)\n","\n","# Data loader (input pipeline)\n","train_loader = th.utils.data.DataLoader(dataset=train_dataset,\n","                                        batch_size=sequence_length * batch_size,\n","                                        shuffle=True)\n","test_loader = th.utils.data.DataLoader(dataset=test_dataset,\n","                                       batch_size=sequence_length * batch_size,\n","                                       shuffle=False)\n","\n","def encode_sequence_data(images, labels):\n","  # Create sequence by chunking along batch dimension.\n","  # [batch, ...] -> [seq_len, batch, ...]\n","  assert images.size(0) % sequence_length == 0\n","  assert labels.size(0) % sequence_length == 0\n","  image_chunks = th.chunk(images, sequence_length)\n","  images = th.stack(image_chunks)\n","  label_chunks = th.chunk(labels, sequence_length)\n","  labels = th.stack(label_chunks)\n","  labels = th.sum(labels, dim=0)  # [seq_len, batch, ...] -> [batch, ...]\n","  return images, labels"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W76Cu2HGNOMd","colab_type":"text"},"cell_type":"markdown","source":["## Model (Conv RNN)"]},{"metadata":{"id":"Mkjmv-dHe0tt","colab_type":"code","colab":{}},"cell_type":"code","source":["# Convolutional neural network (with 2 convolutional layers).\n","class CNN(nn.Module):\n","  def __init__(self, num_outputs):\n","    super().__init__()\n","    self.layer1 = nn.Sequential(\n","        nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n","        nn.BatchNorm2d(16),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2),\n","    )\n","    self.layer2 = nn.Sequential(\n","        nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n","        nn.BatchNorm2d(32),\n","        nn.ReLU(),\n","        nn.MaxPool2d(kernel_size=2, stride=2),\n","    )\n","    self.fc = nn.Linear(7 * 7 * 32, num_outputs)\n","    \n","  def forward(self, x):\n","    out = self.layer1(x)\n","    out = self.layer2(out)\n","    out = out.reshape(out.size(0), -1)\n","    out = self.fc(out)\n","    return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jbhrDxYRNQ5t","colab_type":"code","colab":{}},"cell_type":"code","source":["class ConvRNN(nn.Module):\n","  def __init__(self, conv_net, conv_output_size, hidden_size, num_layers,\n","               num_classes):\n","    super(ConvRNN, self).__init__()\n","    self.conv_net = conv_net\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","    self.lstm = nn.LSTM(conv_output_size, hidden_size, num_layers)\n","    self.fc = nn.Linear(hidden_size, num_classes)\n","    \n","  def forward(self, x):\n","    \"\"\"\n","    Args:\n","      x: input tensor, shaped [seq_len, batch_size, channel, height, width]\n","    \"\"\"\n","    # Set initial hidden and cell states.\n","    h0 = th.zeros(self.num_layers, x.size(1), self.hidden_size).to(device)\n","    c0 = th.zeros(self.num_layers, x.size(1), self.hidden_size).to(device)\n","    \n","    # Apply conv_net to get activations.\n","    orig_shape = x.shape\n","    combined_batch_shape = th.Size([-1]) + x.shape[2:]\n","    x = x.view(*combined_batch_shape)\n","    conv_outs = self.conv_net(x)\n","    conv_outs = conv_outs.view(orig_shape[:2] + th.Size([-1]))\n","    \n","    # Forward propagate LSTM.\n","    # out shape (seq_len, batch_size, hid_size)\n","    out, _ = self.lstm(conv_outs, (h0, c0))\n","    \n","    # Decode the hidden state of the last time step.\n","    out = self.fc(out[-1, :, :])\n","    return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cTL353p6fNeI","colab_type":"code","colab":{}},"cell_type":"code","source":["cnn = CNN(conv_out_size)\n","model = ConvRNN(cnn, conv_out_size, hidden_size, num_layers, num_classes).to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ircl6QxuOwNh","colab_type":"text"},"cell_type":"markdown","source":["## Train"]},{"metadata":{"id":"s_ZPCh7OOx7T","colab_type":"code","outputId":"864f64c4-6ce9-403b-bc2c-11a23fa1e207","executionInfo":{"status":"ok","timestamp":1545710937257,"user_tz":480,"elapsed":40025,"user":{"displayName":"Zhaoyang Xu","photoUrl":"https://lh3.googleusercontent.com/-P706sVVgxyk/AAAAAAAAAAI/AAAAAAAAAEM/nAOSpZonVUE/s64/photo.jpg","userId":"09107292472959224374"}},"colab":{"base_uri":"https://localhost:8080/","height":593}},"cell_type":"code","source":["# Loss and optimizer.\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = th.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","\n","num_steps = len(train_loader)\n","for epoch in range(num_epochs):\n","  for step, (images, labels) in enumerate(train_loader):\n","    images, labels = encode_sequence_data(images, labels)\n","    images = images.to(device)\n","    labels = labels.to(device)\n","\n","    # Forward\n","    outputs = model(images)\n","    loss = loss_fn(outputs, labels)\n","    \n","    # Backward\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if (step + 1) % 100 == 0:\n","      print(f'Epoch [{epoch+1}/{num_epochs}], Step [{step+1}/{num_steps}], '\n","            f'Loss: {loss.item():.4}')  "],"execution_count":96,"outputs":[{"output_type":"stream","text":["Epoch [1/10], Step [100/300], Loss: 2.124\n","Epoch [1/10], Step [200/300], Loss: 1.54\n","Epoch [1/10], Step [300/300], Loss: 1.247\n","Epoch [2/10], Step [100/300], Loss: 0.7427\n","Epoch [2/10], Step [200/300], Loss: 0.5738\n","Epoch [2/10], Step [300/300], Loss: 0.4459\n","Epoch [3/10], Step [100/300], Loss: 0.3697\n","Epoch [3/10], Step [200/300], Loss: 0.333\n","Epoch [3/10], Step [300/300], Loss: 0.3481\n","Epoch [4/10], Step [100/300], Loss: 0.1263\n","Epoch [4/10], Step [200/300], Loss: 0.3218\n","Epoch [4/10], Step [300/300], Loss: 0.09702\n","Epoch [5/10], Step [100/300], Loss: 0.1656\n","Epoch [5/10], Step [200/300], Loss: 0.07498\n","Epoch [5/10], Step [300/300], Loss: 0.0914\n","Epoch [6/10], Step [100/300], Loss: 0.03339\n","Epoch [6/10], Step [200/300], Loss: 0.167\n","Epoch [6/10], Step [300/300], Loss: 0.1996\n","Epoch [7/10], Step [100/300], Loss: 0.09553\n","Epoch [7/10], Step [200/300], Loss: 0.07876\n","Epoch [7/10], Step [300/300], Loss: 0.1219\n","Epoch [8/10], Step [100/300], Loss: 0.05022\n","Epoch [8/10], Step [200/300], Loss: 0.1675\n","Epoch [8/10], Step [300/300], Loss: 0.1133\n","Epoch [9/10], Step [100/300], Loss: 0.03743\n","Epoch [9/10], Step [200/300], Loss: 0.07623\n","Epoch [9/10], Step [300/300], Loss: 0.03776\n","Epoch [10/10], Step [100/300], Loss: 0.0843\n","Epoch [10/10], Step [200/300], Loss: 0.05223\n","Epoch [10/10], Step [300/300], Loss: 0.01835\n"],"name":"stdout"}]},{"metadata":{"id":"votDXSLhR8Be","colab_type":"text"},"cell_type":"markdown","source":["## Test"]},{"metadata":{"id":"6y216f2uR9VQ","colab_type":"code","outputId":"0843d49b-5787-4d15-b83d-f0fdf02e3c1f","executionInfo":{"status":"ok","timestamp":1545711006398,"user_tz":480,"elapsed":564,"user":{"displayName":"Zhaoyang Xu","photoUrl":"https://lh3.googleusercontent.com/-P706sVVgxyk/AAAAAAAAAAI/AAAAAAAAAEM/nAOSpZonVUE/s64/photo.jpg","userId":"09107292472959224374"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"cell_type":"code","source":["with th.no_grad():\n","  correct, total = 0, 0\n","  for images, labels in test_loader:\n","    images, labels = encode_sequence_data(images, labels)\n","    images = images.to(device)\n","    labels = labels.to(device)\n","    outputs = model(images)\n","    _, predicted = th.max(outputs.data, 1)\n","    total += labels.size(0)\n","    correct += (predicted == labels).sum().item()\n","  accuracy = correct / total\n","  print(f'Accuracy of model on 10000 test images: {100 * accuracy:0.2f}%')"],"execution_count":97,"outputs":[{"output_type":"stream","text":["Accuracy of model on 10000 test images: 97.72%\n"],"name":"stdout"}]},{"metadata":{"id":"kWadwB94Wyqe","colab_type":"text"},"cell_type":"markdown","source":["## Save model"]},{"metadata":{"id":"7JzujefLWyGn","colab_type":"code","colab":{}},"cell_type":"code","source":["th.save(model.state_dict(), '/tmp/mnist_rnn.ckpt')"],"execution_count":0,"outputs":[]}]}